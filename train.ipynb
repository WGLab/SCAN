{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from   torch.utils.data import TensorDataset, DataLoader\n",
    "from   torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from scripts.Evaluator     import evaluator\n",
    "from scripts.Generator     import generatorNet\n",
    "from scripts.Discriminator import ensembleNet\n",
    "\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the device is cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('the device is %s' % device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess\n",
    "\n",
    "In this step, the input features will be generated. In detail:\n",
    "1. labeled training data consists of 500 oncogenic variants and 500 benign variants;\n",
    "2. others labeled variants are used as validation set;\n",
    "3. 60,000 unlabeled variants are used for unsupervised training;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_seed           = 37\n",
    "oncogenic_variant_size = 1000\n",
    "benign_variant_size    = 1000\n",
    "batchsize              = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SIFT_score</th>\n",
       "      <th>Polyphen2_HDIV_score</th>\n",
       "      <th>Polyphen2_HVAR_score</th>\n",
       "      <th>LRT_score</th>\n",
       "      <th>MutationTaster_score</th>\n",
       "      <th>MutationAssessor_score</th>\n",
       "      <th>FATHMM_score</th>\n",
       "      <th>PROVEAN_score</th>\n",
       "      <th>VEST3_score</th>\n",
       "      <th>CADD_raw</th>\n",
       "      <th>...</th>\n",
       "      <th>evs_10_2</th>\n",
       "      <th>evs_11_-1</th>\n",
       "      <th>evs_11_0</th>\n",
       "      <th>evs_11_1</th>\n",
       "      <th>evs_11_2</th>\n",
       "      <th>evs_12_-1</th>\n",
       "      <th>evs_12_0</th>\n",
       "      <th>evs_12_1</th>\n",
       "      <th>evs_12_2</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.631809</td>\n",
       "      <td>0.617818</td>\n",
       "      <td>0.497366</td>\n",
       "      <td>0.860861</td>\n",
       "      <td>0.426250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070834</td>\n",
       "      <td>0.098091</td>\n",
       "      <td>0.938011</td>\n",
       "      <td>0.073036</td>\n",
       "      <td>0.070834</td>\n",
       "      <td>0.098091</td>\n",
       "      <td>0.938011</td>\n",
       "      <td>0.073036</td>\n",
       "      <td>0.070834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.694</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.491245</td>\n",
       "      <td>0.672773</td>\n",
       "      <td>0.542581</td>\n",
       "      <td>0.067067</td>\n",
       "      <td>0.442278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077686</td>\n",
       "      <td>0.106276</td>\n",
       "      <td>0.091509</td>\n",
       "      <td>0.916682</td>\n",
       "      <td>0.077686</td>\n",
       "      <td>0.106276</td>\n",
       "      <td>0.091509</td>\n",
       "      <td>0.916682</td>\n",
       "      <td>0.077686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SIFT_score  Polyphen2_HDIV_score  Polyphen2_HVAR_score  LRT_score  \\\n",
       "0       0.012                 0.996                 0.877      0.000   \n",
       "1       0.003                 0.790                 0.365      0.694   \n",
       "\n",
       "   MutationTaster_score  MutationAssessor_score  FATHMM_score  PROVEAN_score  \\\n",
       "0                 0.967                0.631809      0.617818       0.497366   \n",
       "1                 1.000                0.491245      0.672773       0.542581   \n",
       "\n",
       "   VEST3_score  CADD_raw  ...  evs_10_2  evs_11_-1  evs_11_0  evs_11_1  \\\n",
       "0     0.860861  0.426250  ...  0.070834   0.098091  0.938011  0.073036   \n",
       "1     0.067067  0.442278  ...  0.077686   0.106276  0.091509  0.916682   \n",
       "\n",
       "   evs_11_2  evs_12_-1  evs_12_0  evs_12_1  evs_12_2  true_label  \n",
       "0  0.070834   0.098091  0.938011  0.073036  0.070834           0  \n",
       "1  0.077686   0.106276  0.091509  0.916682  0.077686           0  \n",
       "\n",
       "[2 rows x 72 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_unlabeled = pd.read_csv(\"example/training_data/unlabeled_training.dat\")\n",
    "training_labeled   = pd.read_csv(\"example/training_data/labeled_training.dat\")\n",
    "training_labeled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## labeled\n",
    "training_labeled = training_labeled.values\n",
    "\n",
    "np.random.seed(shuffle_seed)\n",
    "np.random.shuffle(training_labeled)\n",
    "\n",
    "labeled_features, labeled_targets = training_labeled[:, :-1], training_labeled[:, -1]\n",
    "\n",
    "training_features   = np.vstack( (labeled_features[labeled_targets == 1][:oncogenic_variant_size], \n",
    "                                  labeled_features[labeled_targets == 0][:benign_variant_size]) )\n",
    "\n",
    "validation_features = np.vstack( (labeled_features[labeled_targets == 1][oncogenic_variant_size:], \n",
    "                                  labeled_features[labeled_targets == 0][benign_variant_size:]) )\n",
    "\n",
    "\n",
    "training_targets    = np.hstack( (labeled_targets[labeled_targets == 1][:oncogenic_variant_size], \n",
    "                                  labeled_targets[labeled_targets == 0][:benign_variant_size]) )\n",
    "\n",
    "validation_targets  = np.hstack( (labeled_targets[labeled_targets == 1][oncogenic_variant_size:], \n",
    "                                  labeled_targets[labeled_targets == 0][benign_variant_size:]) )\n",
    "\n",
    "\n",
    "## unlabeled\n",
    "unlabeled_features = training_unlabeled.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dat       = TensorDataset(torch.Tensor(training_features[:, np.newaxis, :]), torch.Tensor(training_targets).long())\n",
    "training_batch   = DataLoader(dataset=tensor_dat, batch_size = batchsize, shuffle=True)\n",
    "\n",
    "tensor_dat       = TensorDataset(torch.Tensor(validation_features[:, np.newaxis, :]), torch.Tensor(validation_targets).long())\n",
    "validation_batch = DataLoader(dataset=tensor_dat, batch_size = batchsize, shuffle=False)\n",
    "\n",
    "tensor_dat       = TensorDataset(torch.Tensor(unlabeled_features[:, np.newaxis, :]))\n",
    "unlabeled_batch  = DataLoader(dataset=tensor_dat, batch_size = batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model settings\n",
    "- In this step, we used `CrossEntropyLoss` to calculate the loss of supervised learning process. The loss of unsupervised learning are shown in training loop.\n",
    "- We used `LambdaLR` to update learning rate in each epoch. \n",
    "- The scripts of disciminator/generator model are stored in `scripts/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrminator  = ensembleNet().to(device)\n",
    "generator     = generatorNet().to(device)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "optimizerDis  = optim.AdamW(discrminator.parameters(), lr = 0.01)\n",
    "optimizerGen  = optim.AdamW(generator.parameters(), lr = 0.01)\n",
    "\n",
    "schedulerDis  = optim.lr_scheduler.LambdaLR(optimizerDis, lambda epoch: 0.9**epoch)\n",
    "schedulerGen  = optim.lr_scheduler.LambdaLR(optimizerGen, lambda epoch: 0.9**epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training \n",
    "\n",
    "- `tensorboard.SummaryWritter` is used for record the evaluation mertics in each training step;\n",
    "- `num_epochs` is the number of training epoch;\n",
    "- users can save the model stats using `torch.save(discrminator.state_dict(), './saves/myTrain.pt')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [18:59<00:00,  2.28s/it]\n"
     ]
    }
   ],
   "source": [
    "data_fix = time.strftime('%Y-%m-%d_%H-%M')\n",
    "\n",
    "writer = SummaryWriter(comment=data_fix)\n",
    "\n",
    "\n",
    "if not os.path.exists( \"saves/%s\" % data_fix ):\n",
    "    os.mkdir( \"saves/%s\" % data_fix )\n",
    "\n",
    "num_epochs  = 500\n",
    "global_step = 1\n",
    "iter_labeled = iter(training_batch)\n",
    "\n",
    "\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    for step, x_unlabeled in enumerate(unlabeled_batch):\n",
    "\n",
    "        #################################################################################  Classifier/Discriminator \n",
    "        discrminator.train()\n",
    "        generator.eval()\n",
    "        \n",
    "        optimizerDis.zero_grad()\n",
    "        \n",
    "        ## label\n",
    "        try:\n",
    "            x_labeled, y_labeled = next(iter_labeled)\n",
    "            x_labeled, y_labeled = x_labeled.to(device), y_labeled.to(device)\n",
    "        except StopIteration:\n",
    "            iter_labeled = iter(training_batch)\n",
    "            x_labeled, y_labeled = next(iter_labeled)\n",
    "            x_labeled, y_labeled = x_labeled.to(device), y_labeled.to(device)\n",
    "        \n",
    "        \n",
    "        _, outClassLabeled  = discrminator(x_labeled)\n",
    "        lossLabeled      = cross_entropy(outClassLabeled, y_labeled)\n",
    "        \n",
    "        \n",
    "        ## unlabel\n",
    "        x_unlabeled = x_unlabeled[0].to(device)\n",
    "        _, outClassUnlabeled  = discrminator(x_unlabeled)\n",
    "        \n",
    "        logz_unlabeled = torch.logsumexp(outClassUnlabeled, dim=1)\n",
    "        lossUnlabeled  = -0.5 * torch.mean(logz_unlabeled) + 0.5 * torch.mean(F.softplus(logz_unlabeled))\n",
    "        \n",
    "        ## Fake\n",
    "        fakeNoise1       = torch.randn(x_unlabeled.size(0), 30, device=device)\n",
    "        x_Fake1          = ( generator(fakeNoise1) + 1.0 ) / 2\n",
    "        _, outClassFake1 = discrminator(x_Fake1)\n",
    "\n",
    "        logz_fake1 = torch.logsumexp(outClassFake1, dim=1)\n",
    "        lossFake  = 0.5 * torch.mean(F.softplus(logz_fake1))\n",
    "        \n",
    "\n",
    "        ## loss\n",
    "        totalLoss = lossLabeled + lossUnlabeled + lossFake\n",
    "        \n",
    "        ## optimization\n",
    "        writer.add_scalar(\"training_loss/supervised\", lossLabeled, global_step)\n",
    "        writer.add_scalar(\"training_loss/unsupervised\", lossUnlabeled+lossFake, global_step)\n",
    "        writer.add_scalar(\"training_loss/Discriminator\", totalLoss, global_step)\n",
    "\n",
    "        totalLoss.backward()\n",
    "        optimizerDis.step()\n",
    "        \n",
    "                \n",
    "        #################################################################################  Generator\n",
    "        discrminator.eval()\n",
    "        generator.train()\n",
    "        optimizerGen.zero_grad()\n",
    "        \n",
    "        fakeNoise2 = torch.randn(x_unlabeled.size(0), 30, device=device)\n",
    "        x_Fake2    = ( generator(fakeNoise2) + 1.0 ) / 2\n",
    "        \n",
    "        ## loss\n",
    "        y_pred_unlabeled, _ = discrminator(x_unlabeled)\n",
    "        y_pred_fake, _      = discrminator(x_Fake2)\n",
    "        mom_real = torch.mean(y_pred_unlabeled, dim=0)\n",
    "        mom_fake = torch.mean(y_pred_fake, dim=0)\n",
    "        diff = mom_fake * 100 - mom_real * 100\n",
    "        lossG = torch.mean(diff * diff)\n",
    "        \n",
    "        \n",
    "        ## optimization\n",
    "        writer.add_scalar(\"training_loss/Generator\", lossG, global_step)\n",
    "        lossG.backward()        \n",
    "        optimizerGen.step()\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "    \n",
    "    torch.save(discrminator.state_dict(), 'saves/%s/discrminator_epoch%d.pt' % ( data_fix, epoch + 1 ))\n",
    "    torch.save(generator.state_dict(),    'saves/%s/generator_epoch%d.pt' % ( data_fix, epoch + 1 ))\n",
    "    \n",
    "    \n",
    "    training_loss, training_accuracy = evaluator(discrminator, cross_entropy, device, training_batch, False)\n",
    "    writer.add_scalar(\"accuracy/training\",  training_accuracy, epoch)\n",
    "    \n",
    "    validation_loss, validation_accuracy = evaluator(discrminator, cross_entropy, device, validation_batch, False)\n",
    "    writer.add_scalar(\"accuracy/validation\", validation_accuracy, epoch)\n",
    "    writer.flush()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model performance on testing data\n",
    "- we provided a testing set consisting of 6,226 variants with reliable labels;\n",
    "- users can use this testing set to evaluate your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import f1_score \n",
    "import math\n",
    "\n",
    "def myEval(model, device, test_loader, display = False):\n",
    "    model.eval()\n",
    "    \n",
    "    target_list = []\n",
    "    output_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for testdata in test_loader:\n",
    "            data, target = testdata\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            _, output = model(data)\n",
    "            softmax2_score = [ math.exp(i[1]) / ( math.exp(i[0]) + math.exp(i[1]) ) for i in output.cpu().numpy() ]\n",
    "            target_list += target.cpu().tolist()\n",
    "            output_list += softmax2_score\n",
    "\n",
    "    return target_list, output_list\n",
    "\n",
    "\n",
    "def evaluation_df(pred_score, labeled_y):\n",
    "    def TP_table(pred_score, labeled_y, threshold):\n",
    "        y_pred = [0 if i < threshold else 1 for i in pred_score]\n",
    "        y_true = list(labeled_y)\n",
    "\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, pred_score)\n",
    "        auc_val = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        # TP TN FP FN sensitivity specificity Accuracy\n",
    "        sensitivity = tp/(tp+fn)\n",
    "\n",
    "        specificity = tn/(tn+fp)\n",
    "        accuracy    = (tp+tn)/(tp+tn+fp+fn)\n",
    "        \n",
    "        F1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "        try:\n",
    "            MCC = ((tp*tn)-(fp*fn)) / ((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5\n",
    "        except:\n",
    "            MCC = np.nan\n",
    "\n",
    "        return [threshold, tp, fp, tn, fn, sensitivity, specificity, accuracy, auc_val, MCC, F1]\n",
    "\n",
    "    res = []\n",
    "    for i in range(1,20):\n",
    "        threshold = i / 20\n",
    "        res.append(TP_table(pred_score, labeled_y, threshold))\n",
    "\n",
    "    res = pd.DataFrame(res, columns=['threshold', 'TP', 'FP', 'TN', 'FN', 'sen', 'spe', 'Acc', 'AUC', 'MCC', 'F1'])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>sen</th>\n",
       "      <th>spe</th>\n",
       "      <th>Acc</th>\n",
       "      <th>AUC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>1280</td>\n",
       "      <td>3751</td>\n",
       "      <td>1140</td>\n",
       "      <td>55</td>\n",
       "      <td>0.958801</td>\n",
       "      <td>0.233081</td>\n",
       "      <td>0.388693</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.199970</td>\n",
       "      <td>0.402136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1257</td>\n",
       "      <td>3357</td>\n",
       "      <td>1534</td>\n",
       "      <td>78</td>\n",
       "      <td>0.941573</td>\n",
       "      <td>0.313637</td>\n",
       "      <td>0.448281</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.239120</td>\n",
       "      <td>0.422592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>1239</td>\n",
       "      <td>3124</td>\n",
       "      <td>1767</td>\n",
       "      <td>96</td>\n",
       "      <td>0.928090</td>\n",
       "      <td>0.361276</td>\n",
       "      <td>0.482814</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.259351</td>\n",
       "      <td>0.434889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>1222</td>\n",
       "      <td>2958</td>\n",
       "      <td>1933</td>\n",
       "      <td>113</td>\n",
       "      <td>0.915356</td>\n",
       "      <td>0.395216</td>\n",
       "      <td>0.506746</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.271369</td>\n",
       "      <td>0.443155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.25</td>\n",
       "      <td>1207</td>\n",
       "      <td>2835</td>\n",
       "      <td>2056</td>\n",
       "      <td>128</td>\n",
       "      <td>0.904120</td>\n",
       "      <td>0.420364</td>\n",
       "      <td>0.524093</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.279067</td>\n",
       "      <td>0.448949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.30</td>\n",
       "      <td>1199</td>\n",
       "      <td>2699</td>\n",
       "      <td>2192</td>\n",
       "      <td>136</td>\n",
       "      <td>0.898127</td>\n",
       "      <td>0.448170</td>\n",
       "      <td>0.544651</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.293749</td>\n",
       "      <td>0.458246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.35</td>\n",
       "      <td>1193</td>\n",
       "      <td>2606</td>\n",
       "      <td>2285</td>\n",
       "      <td>142</td>\n",
       "      <td>0.893633</td>\n",
       "      <td>0.467185</td>\n",
       "      <td>0.558625</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.303639</td>\n",
       "      <td>0.464745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.40</td>\n",
       "      <td>1187</td>\n",
       "      <td>2514</td>\n",
       "      <td>2377</td>\n",
       "      <td>148</td>\n",
       "      <td>0.889139</td>\n",
       "      <td>0.485995</td>\n",
       "      <td>0.572438</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.313570</td>\n",
       "      <td>0.471406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.45</td>\n",
       "      <td>1175</td>\n",
       "      <td>2411</td>\n",
       "      <td>2480</td>\n",
       "      <td>160</td>\n",
       "      <td>0.880150</td>\n",
       "      <td>0.507054</td>\n",
       "      <td>0.587054</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.321567</td>\n",
       "      <td>0.477545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1162</td>\n",
       "      <td>2291</td>\n",
       "      <td>2600</td>\n",
       "      <td>173</td>\n",
       "      <td>0.870412</td>\n",
       "      <td>0.531589</td>\n",
       "      <td>0.604240</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.331966</td>\n",
       "      <td>0.485380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.55</td>\n",
       "      <td>1147</td>\n",
       "      <td>2191</td>\n",
       "      <td>2700</td>\n",
       "      <td>188</td>\n",
       "      <td>0.859176</td>\n",
       "      <td>0.552034</td>\n",
       "      <td>0.617893</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.338424</td>\n",
       "      <td>0.490905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.60</td>\n",
       "      <td>1134</td>\n",
       "      <td>2093</td>\n",
       "      <td>2798</td>\n",
       "      <td>201</td>\n",
       "      <td>0.849438</td>\n",
       "      <td>0.572071</td>\n",
       "      <td>0.631545</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.346225</td>\n",
       "      <td>0.497150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.65</td>\n",
       "      <td>1119</td>\n",
       "      <td>1980</td>\n",
       "      <td>2911</td>\n",
       "      <td>216</td>\n",
       "      <td>0.838202</td>\n",
       "      <td>0.595175</td>\n",
       "      <td>0.647286</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.355738</td>\n",
       "      <td>0.504736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.70</td>\n",
       "      <td>1109</td>\n",
       "      <td>1869</td>\n",
       "      <td>3022</td>\n",
       "      <td>226</td>\n",
       "      <td>0.830712</td>\n",
       "      <td>0.617870</td>\n",
       "      <td>0.663508</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.368562</td>\n",
       "      <td>0.514259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1083</td>\n",
       "      <td>1747</td>\n",
       "      <td>3144</td>\n",
       "      <td>252</td>\n",
       "      <td>0.811236</td>\n",
       "      <td>0.642813</td>\n",
       "      <td>0.678927</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.374253</td>\n",
       "      <td>0.520048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.80</td>\n",
       "      <td>1057</td>\n",
       "      <td>1610</td>\n",
       "      <td>3281</td>\n",
       "      <td>278</td>\n",
       "      <td>0.791760</td>\n",
       "      <td>0.670824</td>\n",
       "      <td>0.696756</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.383667</td>\n",
       "      <td>0.528236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.85</td>\n",
       "      <td>1020</td>\n",
       "      <td>1418</td>\n",
       "      <td>3473</td>\n",
       "      <td>315</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.710080</td>\n",
       "      <td>0.721651</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.398667</td>\n",
       "      <td>0.540684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.90</td>\n",
       "      <td>982</td>\n",
       "      <td>1157</td>\n",
       "      <td>3734</td>\n",
       "      <td>353</td>\n",
       "      <td>0.735581</td>\n",
       "      <td>0.763443</td>\n",
       "      <td>0.757469</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.431274</td>\n",
       "      <td>0.565343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.95</td>\n",
       "      <td>908</td>\n",
       "      <td>860</td>\n",
       "      <td>4031</td>\n",
       "      <td>427</td>\n",
       "      <td>0.680150</td>\n",
       "      <td>0.824167</td>\n",
       "      <td>0.793286</td>\n",
       "      <td>0.822681</td>\n",
       "      <td>0.459020</td>\n",
       "      <td>0.585240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold    TP    FP    TN   FN       sen       spe       Acc       AUC  \\\n",
       "0        0.05  1280  3751  1140   55  0.958801  0.233081  0.388693  0.822681   \n",
       "1        0.10  1257  3357  1534   78  0.941573  0.313637  0.448281  0.822681   \n",
       "2        0.15  1239  3124  1767   96  0.928090  0.361276  0.482814  0.822681   \n",
       "3        0.20  1222  2958  1933  113  0.915356  0.395216  0.506746  0.822681   \n",
       "4        0.25  1207  2835  2056  128  0.904120  0.420364  0.524093  0.822681   \n",
       "5        0.30  1199  2699  2192  136  0.898127  0.448170  0.544651  0.822681   \n",
       "6        0.35  1193  2606  2285  142  0.893633  0.467185  0.558625  0.822681   \n",
       "7        0.40  1187  2514  2377  148  0.889139  0.485995  0.572438  0.822681   \n",
       "8        0.45  1175  2411  2480  160  0.880150  0.507054  0.587054  0.822681   \n",
       "9        0.50  1162  2291  2600  173  0.870412  0.531589  0.604240  0.822681   \n",
       "10       0.55  1147  2191  2700  188  0.859176  0.552034  0.617893  0.822681   \n",
       "11       0.60  1134  2093  2798  201  0.849438  0.572071  0.631545  0.822681   \n",
       "12       0.65  1119  1980  2911  216  0.838202  0.595175  0.647286  0.822681   \n",
       "13       0.70  1109  1869  3022  226  0.830712  0.617870  0.663508  0.822681   \n",
       "14       0.75  1083  1747  3144  252  0.811236  0.642813  0.678927  0.822681   \n",
       "15       0.80  1057  1610  3281  278  0.791760  0.670824  0.696756  0.822681   \n",
       "16       0.85  1020  1418  3473  315  0.764045  0.710080  0.721651  0.822681   \n",
       "17       0.90   982  1157  3734  353  0.735581  0.763443  0.757469  0.822681   \n",
       "18       0.95   908   860  4031  427  0.680150  0.824167  0.793286  0.822681   \n",
       "\n",
       "         MCC        F1  \n",
       "0   0.199970  0.402136  \n",
       "1   0.239120  0.422592  \n",
       "2   0.259351  0.434889  \n",
       "3   0.271369  0.443155  \n",
       "4   0.279067  0.448949  \n",
       "5   0.293749  0.458246  \n",
       "6   0.303639  0.464745  \n",
       "7   0.313570  0.471406  \n",
       "8   0.321567  0.477545  \n",
       "9   0.331966  0.485380  \n",
       "10  0.338424  0.490905  \n",
       "11  0.346225  0.497150  \n",
       "12  0.355738  0.504736  \n",
       "13  0.368562  0.514259  \n",
       "14  0.374253  0.520048  \n",
       "15  0.383667  0.528236  \n",
       "16  0.398667  0.540684  \n",
       "17  0.431274  0.565343  \n",
       "18  0.459020  0.585240  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_labeled = pd.read_csv(\"example/training_data/labeled_testing.dat\").values\n",
    "labeled_features, labeled_targets = testing_labeled[:, :-1], testing_labeled[:, -1]\n",
    "\n",
    "\n",
    "tensor_dat = TensorDataset(torch.Tensor(labeled_features[:, np.newaxis, :]), torch.Tensor(labeled_targets).long())\n",
    "testing_batch = DataLoader(dataset=tensor_dat, batch_size = batchsize, shuffle=False)\n",
    "\n",
    "label, pred = myEval(discrminator, device, testing_batch)\n",
    "evaluation_df(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STRsignal",
   "language": "python",
   "name": "strsignal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
